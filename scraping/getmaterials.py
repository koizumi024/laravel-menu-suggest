# -*- coding: utf-8 -*-
"""getMaterials.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XheP3SgXsuWk9QcOfwb5ERRE9yxF4ngc
"""

!pip install pykakasi

from google.colab import drive
drive.mount('/content/drive')

from bs4 import BeautifulSoup
from collections import Counter
import requests
import pandas as pd
from pykakasi import kakasi

kakasi = kakasi()
kakasi.setMode('J', 'H') #漢字からひらがなに変換
kakasi.setMode("K", "H") #カタカナからひらがなに変換
conv = kakasi.getConverter()

df = pd.DataFrame([[0, 0, 0]], columns=["material", "hiragana", "menu_id"])
# 検索するレシピ
recipes = ["レシピ１",
"レシピ２",
"レシピ３",
]

menu = 0
for recipe in recipes:
    # HTMLの取得
    url = "https://recipe.rakuten.co.jp/search/" + recipe
    res = requests.get(url)
    html = res.text
    soup = BeautifulSoup(html, 'html.parser')

    materials = soup.findAll("span", {"class":"recipe_ranking__material omit_2line"})

    num = 0
    lists = []
    while num < 50:
        material = materials[num].text
        # 記号類の削除
        replaced_sign = material.replace('●', '').replace('○', '').replace('※', '').replace('◎', '').replace('A', '').replace('Ａ', '').replace('★', '').replace('☆', '').replace('▲', '').replace('　', '').replace('・', '')
        list = (replaced_sign.split('、'))
        lists += list
        num += 1

    
    # HTMLの取得（2ページ目)
    url2 = "https://recipe.rakuten.co.jp/search/" + recipe + "/2"
    res = requests.get(url2)
    html = res.text
    soup = BeautifulSoup(html, 'html.parser')

    materials = soup.findAll("span", {"class":"recipe_ranking__material omit_2line"})
    num = 0
    lists2 = []
    while num < 50:
        material = materials[num].text
        # 記号類の削除
        replaced_sign = material.replace('●', '').replace('○', '').replace('※', '').replace('◎', '').replace('A', '').replace('Ａ', '').replace('★', '').replace('☆', '').replace('▲', '').replace('　', '').replace('・', '').replace('.', '')
        list = (replaced_sign.split('、'))
        lists2 += list
        num += 1
        
    both_page = lists + lists2

    # 出現回数順にソート(20)
    top20 = Counter(both_page).most_common(20)

    # 不適切な食材の削除
    final=[]
    for i in range(0, 20):
        exclude = top20[i][0]
        if exclude != "水" and recipe:
            final.append(exclude)

    # 上位15件のみ抽出
    for i in range(0, 15):
        hiragana = conv.do(final[i])
        df.loc[i+1+menu*15]=[final[i], hiragana, menu+1]
    
    menu += 1
    print(recipe + "のスクレイピング終了")

# CSV出力
# 例: df.to_csv('/content/drive/MyDrive/Colab Notebooks/materials_202112166.csv', encoding="shift jis")
df.to_csv('ファイル名を入力', encoding="shift jis")